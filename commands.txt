### For starting 
./start.sh 

### starting flink
docker-compose exec sql-client ./sql-client.sh

### Creating table in flink
CREATE TABLE courses(
    course_id INT,
    course_name VARCHAR
    ) WITH (
    'connector' = 'kafka',
    'topic' = 'demo.class.courses',
    'properties.bootstrap.servers' = 'broker1:19093',
    'properties.group.id' = 'test-consumer-group',
    'value.format' = 'json',
    'scan.startup.mode' = 'earliest-offset'
    );

canal-json
csv
debezium-json
json
maxwell-json
raw

### see data in flink
select * from courses;

### drop table
drop table courses;

### go into postgres
psql -U postgres -d demo;

### see table
\dt
\dn
select * from class.courses;

### for mongo
mongo
use class;
db.courses.find().limit(5)
db.courses.remove({"course_id" : 1});
MATCH (n:mongo) where n.course_id=2 return n
db.courses.insert({course_id:500,course_name:'one'})
db.courses.update({course_id:1},{$set:{course_name:'abcd'}})


### bind: address already in use - error
sudo lsof -i -P -n | grep LISTEN

### seeing topics
docker exec -it <kafka-container-id> /bin/bash
/usr/bin/kafka-topics --list --zookeeper zookeeper:2181
/usr/bin/kafka-console-consumer --bootstrap-server broker0:19092 --topic demo.class.courses --from-beginning

### seeing connectors
curl localhost:8083/connectors/
curl localhost:8083/connectors/pgsink/status